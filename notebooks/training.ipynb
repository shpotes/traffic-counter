{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shpotes/traffic-counter/blob/dev/notebooks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "BUJgTDNFpnjj",
    "outputId": "fbb6526a-63a3-4305-d9f9-17541776c6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'traffic-counter'...\n",
      "remote: Enumerating objects: 67, done.\u001b[K\n",
      "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 972 (delta 34), reused 45 (delta 15), pack-reused 905\u001b[K\n",
      "Receiving objects: 100% (972/972), 38.22 MiB | 25.04 MiB/s, done.\n",
      "Resolving deltas: 100% (169/169), done.\n",
      "/content/traffic-counter/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd /content/\n",
    "!rm -rf traffic-counter\n",
    "!git clone https://github.com/shpotes/traffic-counter -b dev\n",
    "%cd traffic-counter/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "2tWwbVyvpq9v",
    "outputId": "417c38b5-f3b8-471d-b38c-ff9f24b6c1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (from -r ../requirements.txt (line 1)) (2.0.0rc0)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from -r ../requirements.txt (line 2)) (1.16.5)\n",
      "Requirement already satisfied: opencv-python==4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from -r ../requirements.txt (line 3)) (4.1.0.25)\n",
      "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r ../requirements.txt (line 4)) (0.24.2)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from -r ../requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.14.0.dev2019080601)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.33.6)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.11.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (1.15.0a20190806)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r ../requirements.txt (line 4)) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r ../requirements.txt (line 4)) (2.5.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (41.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (2.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (0.15.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0->-r ../requirements.txt (line 1)) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhhDQU00lRk8"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import gin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, MaxPool2D, Activation, Reshape, ZeroPadding2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from vehicle_nowcasting.data.data_loader import build_source_from_metadata, make_dataset, generate_anchors\n",
    "from vehicle_nowcasting.data.generate_anchors import generate_anchors as gen_anch\n",
    "from vehicle_nowcasting.utils import iou, plot_bb, change_box_order, compute_stride_from_receptive_field\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOE2ppIymd3j"
   },
   "outputs": [],
   "source": [
    "main_dir = '..'\n",
    "data_dir = os.path.join(main_dir, 'data')\n",
    "metadata = pd.read_csv('../data/metadata_test.csv')\n",
    "train = metadata[metadata.split == 'train']\n",
    "val = metadata[metadata.split == 'val']\n",
    "label_map = json.load(open('../data/label_map.json', 'r'))\n",
    "\n",
    "train_sources = build_source_from_metadata(train, label_map, data_dir, mode='train')\n",
    "val_sources = build_source_from_metadata(val, label_map, data_dir, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "xYx4RT82md3p",
    "outputId": "f57939ea-ceb9-4704-9c8b-caf7f08a9483"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 18:08:34.027887 140136917493568 deprecation.py:323] From /home/santiago/anaconda3/envs/CV/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1486: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "train_ds = make_dataset(train_sources, mode='rpn', num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfFh4xCxlRlF"
   },
   "outputs": [],
   "source": [
    "def RPN(inputs, k):\n",
    "    x = ZeroPadding2D(1)(inputs)\n",
    "    x = Conv2D(256, kernel_size=(3, 3),  \n",
    "               activation='relu',\n",
    "               name='window')(x)\n",
    "    cls = Conv2D(k, kernel_size=(1, 1),\n",
    "                 activation='sigmoid',\n",
    "                 name='cls_head')(x)\n",
    "    reg = Conv2D(4 * k, kernel_size=(1, 1),\n",
    "                 name='reg_head')(x)\n",
    "    return Concatenate()([cls, reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15ldRbNHlRlO"
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "backbone_model = VGG16(input_tensor=inputs,\n",
    "                       weights='imagenet',\n",
    "                       include_top=False)\n",
    "x = backbone_model.output\n",
    "model = Model(inputs=inputs, outputs=RPN(x, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "colab_type": "code",
    "id": "N1N_1r5clRlV",
    "outputId": "6382737e-d14d-49f2-c1f2-46559db7bebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 9, 9, 512)    0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "window (Conv2D)                 (None, 7, 7, 256)    1179904     zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "cls_head (Conv2D)               (None, 7, 7, 15)     3855        window[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reg_head (Conv2D)               (None, 7, 7, 60)     15420       window[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 7, 7, 75)     0           cls_head[0][0]                   \n",
      "                                                                 reg_head[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 15,913,867\n",
      "Trainable params: 15,913,867\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5shRzQkyBhK"
   },
   "outputs": [],
   "source": [
    "y_true = next(iter(train_ds.batch(1)))[1]\n",
    "p_true = y_true[:, :, :, :2 * k]\n",
    "t_gt = y_true[:, :, :, 2 * k: 6 * k]\n",
    "t_bb = y_true[:, :, :, 6 * k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1127, shape=(11, 4), dtype=int64, numpy=\n",
       "array([[ 0,  0,  4, 12],\n",
       "       [ 0,  2,  3,  4],\n",
       "       [ 0,  3,  2,  1],\n",
       "       [ 0,  3,  3,  4],\n",
       "       [ 0,  4,  1, 12],\n",
       "       [ 0,  4,  2,  0],\n",
       "       [ 0,  5,  1,  1],\n",
       "       [ 0,  5,  1,  3],\n",
       "       [ 0,  5,  1,  6],\n",
       "       [ 0,  5,  2,  0],\n",
       "       [ 0,  5,  3,  0]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_true[:, :, :, 1::2].shape) # 1 if positive example\n",
    "tf.where(p_true[:, :, :, 1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mask = p_true[:, :, :, 1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_true = tf.reduce_max(tf.reshape(p_true, (1, 7, 7, k, 2)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(tf.zeros((1, 224, 224, 3)))\n",
    "p_pred = y_pred[:, :, :, :k]\n",
    "t_pred = y_pred[:, :, :, k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1314, shape=(), dtype=float32, numpy=34.340233>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.losses.binary_crossentropy(p_true, p_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_parametrization(_t, t_a):\n",
    "    _t = tf.cast(tf.reshape(_t, (-1, 7, 7, k, 4)), tf.float64)\n",
    "    t_a = tf.cast(tf.reshape(t_a, (-1, 7, 7, k, 4)), tf.float64)\n",
    "    t_xy = _t[:, :, :, :, :2]\n",
    "    t_wh = _t[:, :, :, :, 2:]\n",
    "    t_a_xy = t_a[:, :, :, :,  :2]\n",
    "    t_a_wh = t_a[:, :, :, :, 2:]\n",
    "    \n",
    "    t_xy = (t_xy - t_a_xy) / t_wh\n",
    "\n",
    "    t_wh = tf.math.log(t_wh / t_a_wh)\n",
    "\n",
    "    t = tf.concat([t_xy, t_wh], axis=-1)\n",
    "\n",
    "    t = tf.where(tf.math.is_nan(t), tf.zeros_like(t), t)\n",
    "    t = tf.where(tf.math.is_inf(t), tf.zeros_like(t), t)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_true = reg_parametrization(t_gt, t_bb)\n",
    "t_pred = reg_parametrization(t_pred, t_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_smooth(x):\n",
    "    return tf.where(tf.math.abs(x) < 1, 0.5 * x * x, tf.math.abs(x) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1396, shape=(), dtype=float64, numpy=3197.066420150232>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reshape(p_mask, (1, 7, 7, k, 1)) * l1_smooth(t_true - t_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPN_loss(k, y_true, y_pred):\n",
    "    p_true = y_true[:, :, :, :2 * k]\n",
    "    t_gt = y_true[:, :, :, 2 * k: 6 * k]\n",
    "    t_bb = y_true[:, :, :, 6 * k:]\n",
    "    \n",
    "    p_pred = y_pred[:, :, :, :k]\n",
    "    t_pred = y_pred[:, :, :, k:]\n",
    "    \n",
    "    p_mask = p_true[:, :, :, 1::2]\n",
    "    p_true = tf.reduce_max(tf.reshape(p_true, (-1, 7, 7, k, 2)), axis=-1)\n",
    "    \n",
    "    cls_loss = tf.losses.binary_crossentropy(p_true, p_pred)\n",
    "    cls_loss = tf.identity(cls_loss, name='cls_loss')\n",
    "    \n",
    "    t_true = reg_parametrization(t_gt, t_bb)\n",
    "    t_pred = reg_parametrization(t_pred, t_bb)\n",
    "    \n",
    "    reg_loss = l1_smooth(t_true - t_pred)\n",
    "    reg_loss = tf.cast(reg_loss, tf.float32)\n",
    "    \n",
    "    reg_loss = tf.identity(reg_loss, name='reg_loss')\n",
    "    \n",
    "    p_true = tf.reshape(p_true, (-1, 7, 7, k, 1))\n",
    "    \n",
    "    return 1 * tf.math.reduce_sum(cls_loss) # +  0 * tf.math.reduce_sum(p_true * reg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/10 [==============>...............] - ETA: 13s - loss: nan"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=3e-4)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=lambda y_true, y_pred: RPN_loss(15, y_true, y_pred))\n",
    "\n",
    "hist = model.fit_generator(train_ds.batch(1).repeat(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
